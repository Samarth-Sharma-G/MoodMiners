{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing\n",
    "We trained two models in the '03_Model' stage directory notebook.\n",
    "\n",
    "1. A gradient boosting model.\n",
    "    > On the emotion feature\n",
    "2. A random forest classifier.\n",
    "    > On the emotion and emotional intensity feature.\n",
    "\n",
    "In this notebook, we will assess the strengths and weaknessess of our chosen models in the previous stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_emotion = pd.read_csv('X_test_emotion.csv')\n",
    "y_test_emotion = pd.read_csv('y_test_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_emotional_intensity = pd.read_csv('X_test_emotional_intensity.csv')\n",
    "y_test_emotional_intensity = pd.read_csv('y_test_emotional_intensity.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model weights from the pickle model\n",
    "with open('../04_Model/gb_classifier_emotion.pkl', 'rb') as file:\n",
    "    gb_classifier_emotion = pickle.load(file)\n",
    "\n",
    "with open('../04_Model/rf_classifier_emotion.pkl', 'rb') as file:\n",
    "    rf_classifier_emotion = pickle.load(file)\n",
    "\n",
    "with open('../04_Model/rf_classifier_emotional_intensity.pkl', 'rb') as file:\n",
    "    rf_classifier_emotional_intensity = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing the Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the test set\n",
    "y_pred_gb_simple = gb_classifier_emotion.predict(X_test_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.39      0.47        23\n",
      "           2       0.62      0.69      0.65        35\n",
      "           3       0.45      0.23      0.31        43\n",
      "           4       0.33      0.37      0.34        41\n",
      "           5       0.70      0.70      0.70        37\n",
      "           6       0.44      0.61      0.51        33\n",
      "           7       0.50      0.61      0.55        31\n",
      "           8       0.52      0.53      0.53        45\n",
      "\n",
      "    accuracy                           0.51       288\n",
      "   macro avg       0.52      0.52      0.51       288\n",
      "weighted avg       0.51      0.51      0.50       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_emotion, y_pred_gb_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5104166666666666"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_classifier_emotion.score(X_test_emotion, y_test_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5104166666666666, 0.5206129130042174, 0.516303787439367, 0.5085716417188839)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating Accuracy, Precision, Recall, and F1 Score for the Gradient Boosting model\n",
    "accuracy_gb = accuracy_score(y_test_emotion, y_pred_gb_simple)\n",
    "precision_gb = precision_score(y_test_emotion, y_pred_gb_simple, average='macro')\n",
    "recall_gb = recall_score(y_test_emotion, y_pred_gb_simple, average='macro')\n",
    "f1_score_gb = f1_score(y_test_emotion, y_pred_gb_simple, average='macro')\n",
    "\n",
    "accuracy_gb, precision_gb, recall_gb, f1_score_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_simple = rf_classifier_emotion.predict(X_test_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.43      0.53        23\n",
      "           2       0.62      0.89      0.73        35\n",
      "           3       0.45      0.35      0.39        43\n",
      "           4       0.45      0.41      0.43        41\n",
      "           5       0.71      0.68      0.69        37\n",
      "           6       0.46      0.55      0.50        33\n",
      "           7       0.47      0.55      0.51        31\n",
      "           8       0.60      0.56      0.57        45\n",
      "\n",
      "    accuracy                           0.55       288\n",
      "   macro avg       0.55      0.55      0.54       288\n",
      "weighted avg       0.55      0.55      0.54       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_emotion, y_pred_rf_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5486111111111112"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier_emotion.score(X_test_emotion, y_test_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5486111111111112,\n",
       " 0.5539831294436557,\n",
       " 0.5511301404392122,\n",
       " 0.5446829897262553)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating Accuracy, Precision, Recall, and F1 Score for the Random Forest model for emotion\n",
    "accuracy_rf_emotion = accuracy_score(y_test_emotion, y_pred_rf_simple)\n",
    "precision_rf_emotion = precision_score(y_test_emotion, y_pred_rf_simple, average='macro')\n",
    "recall_rf_emotion = recall_score(y_test_emotion, y_pred_rf_simple, average='macro')\n",
    "f1_score_rf_emotion = f1_score(y_test_emotion, y_pred_rf_simple, average='macro')\n",
    "\n",
    "accuracy_rf_emotion, precision_rf_emotion, recall_rf_emotion, f1_score_rf_emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Emotional Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_best = rf_classifier_emotional_intensity.predict(X_test_emotional_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.81       150\n",
      "           1       0.88      0.63      0.73       138\n",
      "\n",
      "    accuracy                           0.78       288\n",
      "   macro avg       0.80      0.78      0.77       288\n",
      "weighted avg       0.80      0.78      0.78       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_emotional_intensity, y_pred_rf_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78125"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier_emotional_intensity.score(X_test_emotional_intensity,y_test_emotional_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.78125, 0.8044733044733045, 0.7752173913043479, 0.7741682536126359)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating Accuracy, Precision, Recall, and F1 Score for the Random Forest model for Emotional Intensity\n",
    "accuracy_rf_emotional_intensity = accuracy_score(y_test_emotional_intensity, y_pred_rf_best)\n",
    "precision_rf_emotional_intensity = precision_score(y_test_emotional_intensity, y_pred_rf_best, average='macro')\n",
    "recall_rf_emotional_intensity = recall_score(y_test_emotional_intensity, y_pred_rf_best, average='macro')\n",
    "f1_score_rf_emotional_intensity = f1_score(y_test_emotional_intensity, y_pred_rf_best, average='macro')\n",
    "\n",
    "accuracy_rf_emotional_intensity, precision_rf_emotional_intensity, recall_rf_emotional_intensity, f1_score_rf_emotional_intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC plot for all three models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Emotion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_gb_emotion = roc_auc_score(y_test_emotion, gb_classifier_emotion.predict_proba(X_test_emotion), multi_class='ovr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/mocha/DataspellProjects/CMPE255_Assignments/MoodMiners/05_Assess/Assessing.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mocha/DataspellProjects/CMPE255_Assignments/MoodMiners/05_Assess/Assessing.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m auc_gb_emotion \u001b[39m=\u001b[39m roc_auc_score(y_test_emotion, gb_classifier_emotion\u001b[39m.\u001b[39mpredict_proba(X_test_emotion), multi_class\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39movr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mocha/DataspellProjects/CMPE255_Assignments/MoodMiners/05_Assess/Assessing.ipynb#X44sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Calculate the false positive rate and true positive rate for each model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mocha/DataspellProjects/CMPE255_Assignments/MoodMiners/05_Assess/Assessing.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m fpr_rf_emotion, tpr_rf_emotion, _ \u001b[39m=\u001b[39m roc_curve(y_test_emotion, rf_classifier_emotion\u001b[39m.\u001b[39;49mpredict_proba(X_test_emotion)[:, \u001b[39m1\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mocha/DataspellProjects/CMPE255_Assignments/MoodMiners/05_Assess/Assessing.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m fpr_rf_emotional_intensity, tpr_rf_emotional_intensity, _ \u001b[39m=\u001b[39m roc_curve(y_test_emotional_intensity, rf_classifier_emotional_intensity\u001b[39m.\u001b[39mpredict_proba(X_test_emotional_intensity)[:, \u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mocha/DataspellProjects/CMPE255_Assignments/MoodMiners/05_Assess/Assessing.ipynb#X44sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m fpr_gb_emotion, tpr_gb_emotion, _ \u001b[39m=\u001b[39m roc_curve(y_test_emotion, gb_classifier_emotion\u001b[39m.\u001b[39mpredict_proba(X_test_emotion)[:, \u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/envs/audio-analysis/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:981\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroc_curve\u001b[39m(\n\u001b[1;32m    893\u001b[0m     y_true, y_score, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    894\u001b[0m ):\n\u001b[1;32m    895\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \n\u001b[1;32m    897\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    979\u001b[0m \n\u001b[1;32m    980\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[1;32m    982\u001b[0m         y_true, y_score, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[1;32m    983\u001b[0m     )\n\u001b[1;32m    985\u001b[0m     \u001b[39m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    986\u001b[0m     \u001b[39m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    987\u001b[0m     \u001b[39m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[39m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m    993\u001b[0m     \u001b[39m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/envs/audio-analysis/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:740\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    738\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    739\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[0;32m--> 740\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[1;32m    742\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    743\u001b[0m y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the AUC scores for each model\n",
    "auc_rf_emotion = roc_auc_score(y_test_emotion,rf_classifier_emotion.predict_proba(X_test_emotion), multi_class='ovr')\n",
    "auc_rf_emotional_intensity = roc_auc_score(y_test_emotional_intensity, rf_classifier_emotional_intensity.predict_proba(X_test_emotional_intensity)[:, 1])\n",
    "\n",
    "\n",
    "# Calculate the false positive rate and true positive rate for each model\n",
    "fpr_rf_emotion, tpr_rf_emotion, _ = roc_curve(y_test_emotion, rf_classifier_emotion.predict_proba(X_test_emotion)[:, 1])\n",
    "fpr_rf_emotional_intensity, tpr_rf_emotional_intensity, _ = roc_curve(y_test_emotional_intensity, rf_classifier_emotional_intensity.predict_proba(X_test_emotional_intensity)[:, 1])\n",
    "fpr_gb_emotion, tpr_gb_emotion, _ = roc_curve(y_test_emotion, gb_classifier_emotion.predict_proba(X_test_emotion)[:, 1])\n",
    "\n",
    "# Plot the ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_rf_emotion, tpr_rf_emotion, label='Random Forest (Emotion) - AUC = {:.2f}'.format(auc_rf_emotion))\n",
    "plt.plot(fpr_rf_emotional_intensity, tpr_rf_emotional_intensity, label='Random Forest (Emotional Intensity) - AUC = {:.2f}'.format(auc_rf_emotional_intensity))\n",
    "plt.plot(fpr_gb_emotion, tpr_gb_emotion, label='Gradient Boosting (Emotion) - AUC = {:.2f}'.format(auc_gb_emotion))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8813881689371361"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test_emotion,rf_classifier_emotion.predict_proba(X_test_emotion), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier_emotion.predict_proba(X_test_emotion)[:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "8          45\n",
       "3          43\n",
       "4          41\n",
       "5          37\n",
       "2          35\n",
       "6          33\n",
       "7          31\n",
       "1          23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
